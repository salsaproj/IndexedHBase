package iu.pti.hbaseapp.truthy.streaming;

import iu.pti.hbaseapp.truthy.streaming.MemeClusteringTester.GlobalClusteringParams;

import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.FileReader;
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Set;

import com.google.gson.Gson;

/**
 * Container for methods related to computation of LFK-NMI between two clustering results. 
 * @author gaoxm
 */
public class NmiUtil {
	/**
	 * A condensed representation of an overlap matrix. For any two clusters with overlaps, the matrix records the 
	 * IDs of the two clusters, and the corresponding overlap size, i.e. number of nodes (tweet IDs) shared by them.
	 * @author gaoxm
	 */
	public static class OverlapMatrix {
		/** A map from cluster IDs in one clustering result to information about all the overlapping clusters in another
		 * clustering result. The 'information about overlapping clusters' is also encoded in a map from the overlapping
		 * cluster IDs to the size of the corresponding overlaps (number of nodes or tweet IDs in the intersection). 
		 */
		protected Map<Integer, Map<Integer, Integer>> cidToOlSizeMap;
		protected int N;
		
		public OverlapMatrix() {
			cidToOlSizeMap = new HashMap<Integer, Map<Integer, Integer>>();
			N = 0;
		}
		
		/**
		 * Construct an overlap matrix between the clusters generated by two different clustering processes.
		 * @param tidToCluster1
		 *  A map from tweet IDs to cluster IDs, a 'reverse' representation of one clustering process result.
		 * @param tidToCluster2
		 *  A map from tweet IDs to cluster IDs, a 'reverse' representation of another clustering process result.
		 */
		public OverlapMatrix(Map<String, Set<Integer>> tidToCluster1, Map<String, Set<Integer>> tidToCluster2) {
			cidToOlSizeMap = new HashMap<Integer, Map<Integer, Integer>>();
			Set<String> allTids = new HashSet<String>();
			allTids.addAll(tidToCluster1.keySet());
			allTids.addAll(tidToCluster2.keySet());
			N = allTids.size();
			
			for (String tid : allTids) {
				Set<Integer> s1 = tidToCluster1.get(tid);
				Set<Integer> s2 = tidToCluster2.get(tid);
				if (s1 != null && s2 != null) {
					for (Integer cid1 : s1) {
						for (Integer cid2 : s2) {
							Map<Integer, Integer> olSizeMap = cidToOlSizeMap.get(cid1);
							if (olSizeMap == null) {
								olSizeMap = new HashMap<Integer, Integer>();
								cidToOlSizeMap.put(cid1, olSizeMap);
							}
							Integer olsize = olSizeMap.get(cid2);
							if (olsize == null) {
								olSizeMap.put(cid2, 1);
							} else {
								olSizeMap.put(cid2, olsize + 1);
							}
						}
					}
				}
			}
			
			/*
			System.out.println("Overlap matrix:");
			for (Map.Entry<Integer, Map<Integer, Integer>> e : cidToOlSizeMap.entrySet()) {
				int cid1 = e.getKey();
				for (Map.Entry<Integer, Integer> ole : e.getValue().entrySet()) {
					int cid2 = ole.getKey();
					int size = ole.getValue();
					System.out.print("[" + cid1 + "-" + cid2 + ":" + size + "] ");
				}
				System.out.println();
			}*/
		}
		
		/**
		 * Flip the two cluster IDs of each pair of overlapping clusters in this overlap matrix, and return
		 * 'flipped' matrix.
		 * @return
		 */
		public OverlapMatrix getFlippedOM() {
			OverlapMatrix om2 = new OverlapMatrix();
			om2.N = N;
			for (Map.Entry<Integer, Map<Integer, Integer>> e : cidToOlSizeMap.entrySet()) {
				int cid1 = e.getKey();
				Map<Integer, Integer> olSizeMap = e.getValue();
				for (Map.Entry<Integer, Integer> eol : olSizeMap.entrySet()) {
					int cid2 = eol.getKey();
					int olsize = eol.getValue();
					
					Map<Integer, Integer> resOlSizeMap = om2.cidToOlSizeMap.get(cid2);
					if (resOlSizeMap == null) {
						resOlSizeMap = new HashMap<Integer, Integer>();
						om2.cidToOlSizeMap.put(cid2, resOlSizeMap);
					}
					resOlSizeMap.put(cid1, olsize);
				}
			}
			
			/*
			System.out.println("Flipped overlap matrix:");
			for (Map.Entry<Integer, Map<Integer, Integer>> e : om2.cidToOlSizeMap.entrySet()) {
				int cid1 = e.getKey();
				for (Map.Entry<Integer, Integer> ole : e.getValue().entrySet()) {
					int cid2 = ole.getKey();
					int size = ole.getValue();
					System.out.print("[" + cid1 + "-" + cid2 + ":" + size + "] ");
				}
				System.out.println();
			}*/
			
			return om2;
		}
	}
	
	/**
	 * Convert an array of tweet ID clusters into a 'reverse' map from tweet IDs to the cluster IDs.
	 * @param tidClusters
	 * @return
	 */
	protected Map<String, Set<Integer>> getTidToClusterMap(Set<String>[] tidClusters) {
		Map<String, Set<Integer>> tidToCluster = new HashMap<String, Set<Integer>>();
		for (int cid=0; cid<tidClusters.length; cid++) {
			Set<String> cluster = tidClusters[cid];
			if (cluster == null) {
				continue;
			}
			for (String tid : cluster) {
				Set<Integer> clusterIds = tidToCluster.get(tid);
				if (clusterIds == null) {
					clusterIds = new HashSet<Integer>();
					tidToCluster.put(tid, clusterIds);
				}
				clusterIds.add(cid);
			}
		}
		return tidToCluster;
	}
	
	protected double H(int x, int N) throws IllegalArgumentException {
		if (x < 0 || N < 0 || x > N) {
			throw new IllegalArgumentException("Invalid x or N values.");
		}
		if (x == 0) {
			return 0.0;
		}
		double px = (double)x / (double)N;
		return -px * Math.log(px) / Math.log(2);
	}
	
	protected double h(double p) throws IllegalArgumentException {
		if (p < 0) {
			throw new IllegalArgumentException("Invalid p value.");
		}
		if(p==0)
			return 0;
		
		return -p * Math.log(p) / Math.log(2);
	}
	
	protected double getHXgivenY(int y, int x, int o, int N) throws IllegalArgumentException {
		// the NON-NORMALIZED mutual information
		// given sets of size 'x' and 'y', where there are 'o' nodes in common, what's their similarity score?
		if (o <= 0 || y < o || x < o || y > N || x > N) {
			throw new IllegalArgumentException("Invalid y, x, o or N values.");
		}
		//System.out.println("HXgivenY: size(X): " + x + ", size(Y):" + y + ", size(overlap):" + o);
		
		double H_Y = H(y,N) + H(N-y,N);
		double H_X = H(x,N) + H(N-x,N);
		double pX0Y0 = (N-x-y+o) / (double)N;
		double pX1Y0 = (x-o) / (double)N;
		double pX0Y1 = (y-o) / (double)N;
		double pX1Y1 = o / (double)N;
		double hPX0Y0 = h(pX0Y0);
		double hPX1Y0 = h(pX1Y0);
		double hPX0Y1 = h(pX0Y1);
		double hPX1Y1 = h(pX1Y1);
		
		//System.out.println("HXgivenY: H(X): " + H_X + ", H(Y):" + H_Y);
		//System.out.println("HXgivenY: h(pX0Y0): " + hPX0Y0 + ", h(pX1Y1):" + hPX1Y1 + ", h(pX0Y1):" + hPX0Y1 + ",h(pX1Y0):" + hPX1Y0);
		if(hPX0Y0+hPX1Y1 <= hPX0Y1+hPX1Y0) {
			//System.out.println("HXgivenY: returning H(X) because 'h(pX0Y0)+h(pX1Y1) <= h(pX0Y1)+h(pX1Y0)'.");
			return H_X;
		}
		double H_XY = hPX0Y0 + hPX1Y1 + hPX0Y1 + hPX1Y0;
		//System.out.println("HXgivenY: H(X,Y): " + H_XY);
		if(H_X < H_XY - H_Y) { // this shouldn't really happen, except by a roundoff error
			//System.out.println("HXgivenY: retruning H(X): " + H_X);
			return H_X;
		} else {
			//System.out.println("HXgivenY: retruning H(X,Y)-H(Y): " + (H_XY - H_Y));
			return H_XY - H_Y;
		}
	}
	
	protected double findHXgivenBestY(OverlapMatrix om, Set<String>[] clusteringY, Set<String>[] clusteringX, int xCid) 
		throws Exception {
		// xCid is a cluster ID in clusteringX.
		// we're looking for the bits to encode X_realxId given all of Y
		int sizeOfXCluster = clusteringX[xCid].size();
		double bestSoFar = H(sizeOfXCluster, om.N) + H(om.N-sizeOfXCluster, om.N);
		Map<Integer, Integer> olSizeMap = om.cidToOlSizeMap.get(xCid);
		if (olSizeMap != null) {
			for (Map.Entry<Integer, Integer> e : olSizeMap.entrySet()) {
				int yCid = e.getKey();
				int olsize = e.getValue();
				//System.out.println("======Computing H(X|Y) between cluster X-" + xCid + " and Y-" + yCid);
				double tmp = getHXgivenY(clusteringY[yCid].size(), clusteringX[xCid].size(), olsize, om.N);
				if (tmp < bestSoFar) {
					bestSoFar = tmp;
				}
			}
		}
		//System.out.println("HXgivenBestY for cluster X-" + xCid + ": " + bestSoFar);
		return bestSoFar;
	}
	
	protected double VIoneSide(OverlapMatrix om, Set<String>[] clusteringY, Set<String>[] clusteringX) throws Exception {
		// this doesn't return the (N)MI. It's the non-mutual information
		int N = om.N;
		double total = 0.0;
		for (int xCid = 0; xCid < clusteringX.length; xCid++) {
			double unnorm = findHXgivenBestY(om, clusteringY, clusteringX, xCid);
			int x = clusteringX[xCid].size();
			double H_X = H(x, N) + H(N - x, N);
			if (H_X == 0.0) { 
				// the communities take up the whole set of nodes, and hence won't need any bits to be encoded. No need to add anything to 'total'
				assert (unnorm == 0.0);
				// in this case norm is 0/0, but we'll just define this as 1
				total += 1.0;
			} else {
				double norm = unnorm / H_X;
				assert (norm <= 1.01);
				assert (norm >= -0.01);
				total += norm;
			}
		}
		//System.out.println("Varied information from one side: " + total / clusteringX.length);
		return total / clusteringX.length;
	}
	
	/**
	 * Compute the LFK-NMI between <b>clusters</b> and <b>groundTruthClusters</b>.
	 * @param clusters
	 *  An array of protomeme clusters.
	 * @param groundTruthClusters
	 *  A map from ground truth hashtags to the set of tweet IDs containing each hashtag.
	 * @return
	 *  The LFK-NMI value.
	 * @throws Exception
	 */
	public double computeLfkNmi(List<ProtomemeCluster> clusters, Map<String, Set<String>> groundTruthClusters) throws Exception {
		if (groundTruthClusters.size() == 0) {
			return 0.0;
		}
		
		List<Set<String>> cList = new ArrayList<Set<String>>();
		for (int i=0; i<clusters.size(); i++) {
			ProtomemeCluster pmc = clusters.get(i);
			if (pmc != null) {
				Set<String> c = new HashSet<String>();
				c.addAll(pmc.centTidVector.keySet());
				cList.add(c);
			}
		}
		Set<String>[] resClusters = new Set[cList.size()];
		resClusters = cList.toArray(resClusters);
		
		cList.clear();
		for (Set<String> gtc : groundTruthClusters.values()) {
			if (gtc.size() > 0) {
				Set<String> c = new HashSet<String>();
				c.addAll(gtc);
				cList.add(c);
			}
		}
		Set<String>[] gtClusters = new Set[cList.size()];
		gtClusters = cList.toArray(gtClusters);
		Map<String, Set<Integer>> resTidToClusters = getTidToClusterMap(resClusters);
		Map<String, Set<Integer>> gtTidToClusters = getTidToClusterMap(gtClusters);
		OverlapMatrix om = new OverlapMatrix(resTidToClusters, gtTidToClusters);
		OverlapMatrix omFlipped = om.getFlippedOM();
		
		return 1.0 - 0.5 * (VIoneSide(omFlipped, resClusters, gtClusters) + VIoneSide(om, gtClusters, resClusters));
	}
	
	/**
	 * Compute the LFK-NMI between the clusters in <b>clusterPath1</b> and <b>clusterPath2</b>.
	 * @param clusterPath1
	 *  Path to one file describing a list of clusters.
	 * @param clusterPath2
	 *  Path to another file describing a list of clusters.
	 * @return
	 *  The LFK-NMI value.
	 * @throws Exception
	 */
	public double testLfkNmiWithFiles(String clusterPath1, String clusterPath2) throws Exception {
		List<Set<String>> cList = readClusterFromTestFile(clusterPath1);
		Set<String>[] clusteringX = new Set[cList.size()];
		clusteringX = cList.toArray(clusteringX);

		List<Set<String>> cList2 = readClusterFromTestFile(clusterPath2);
		Set<String>[] clusteringY = new Set[cList2.size()];
		clusteringY = cList2.toArray(clusteringY);
		
		Map<String, Set<Integer>> tidToClusters1 = getTidToClusterMap(clusteringX);
		Map<String, Set<Integer>> tidToClusters2 = getTidToClusterMap(clusteringY);
		OverlapMatrix om = new OverlapMatrix(tidToClusters1, tidToClusters2);
		OverlapMatrix omFlipped = om.getFlippedOM();
		double res = 1.0 - 0.5 * (VIoneSide(omFlipped, clusteringX, clusteringY) + VIoneSide(om, clusteringY, clusteringX));
		System.out.println("LFK-NMI between " + clusterPath1 + " and " + clusterPath2 + ": " + res);
		return res;
	}

	/**
	 * Read clusters from <b>clusterPath</b>. Each line in the file describes one cluster,
	 * in the form of a comma separated list of node names.
	 * @param clusterPath
	 *  Path to a file describing a list of clusters.
	 * @return
	 *  A list of clusters, each represented as a set of node name strings.
	 * @throws Exception
	 */
	protected List<Set<String>> readClusterFromTestFile(String clusterPath) throws Exception {
		List<Set<String>> cList = new LinkedList<Set<String>>();
		BufferedReader br = new BufferedReader(new FileReader(clusterPath));
		String line = br.readLine();
		while (line != null) {
			line = line.trim();
			if (line.length() > 0) {
				// every line is a cluster, i.e. node name separated by commas
				String[] nodes = line.replaceAll("^[,\\s]+", "").split("[,\\s]+");
				Set<String> nodeSet = new HashSet<String>(nodes.length);
				for (String n : nodes) {
					nodeSet.add(n);
				}
				cList.add(nodeSet);
			}
			line = br.readLine();
		}
		br.close();
		return cList;
	}
	
	/**
	 * Read protomeme clusters from <b>olkResPath</b> and generate clusters of tweet IDs.
	 * @param olkResPath
	 *  Path to the output of an online K-means sliding window algorithm.
	 * @return
	 *  A list of clusters, each represented by a set of tweet ID strings.
	 * @throws Exception
	 */
	protected List<Set<String>> readClusterFromOlkResFile(String olkResPath) throws Exception {
		BufferedReader brOlkRes = new BufferedReader(new InputStreamReader(new FileInputStream(olkResPath), "UTF-8"));
		//1st line: "Final values of global parameters:"
		String line = brOlkRes.readLine();
		
		//2nd line: JSON string of GlobalClusteringParams
		line = brOlkRes.readLine();
		
		//3rd line: "Protomemes in the final 120 clusters:"
		line = brOlkRes.readLine();
		int idx2 = line.lastIndexOf(' ');
		int idx1 = line.lastIndexOf(' ', idx2-1);
		int clusterNum = Integer.parseInt(line.substring(idx1+1, idx2));
		List<Set<String>> tidClusters = new ArrayList<Set<String>>(clusterNum);
		
		Set<String> tmpCluster = null;
		Gson gson = new Gson();
		// from now on: either "Cluster-*" or JSON string for a protomeme in Cluster-*
		line = brOlkRes.readLine();
		while (line != null) {
			if (line.startsWith("Cluster-")) {
				tmpCluster = new HashSet<String>();
				int clusterId = Integer.parseInt(line.substring("Cluster-".length()));
				//tidClusters.set(clusterId, tmpCluster);
				tidClusters.add(tmpCluster);
			} else {
				ProtoMeme pm = gson.fromJson(line, ProtoMeme.class);
				tmpCluster.addAll(pm.tweetIds);
			}
			line = brOlkRes.readLine();
		}
		brOlkRes.close();
		
		return tidClusters;
	}
	
	/**
	 * Compute the LFK-NMI value between the results of two online K-Means sliding window algorithms.
	 * @param olkResPath1
	 *  Path to the output of one online K-means sliding window algorithm.
	 * @param olkResPath2
	 *  Path to the output of another online K-means sliding window algorithm.
	 * @return
	 *  The LFK-NMI value.
	 * @throws Exception
	 */
	public double getLfkNmiBetweenOlkRes(String olkResPath1, String olkResPath2) throws Exception {
		List<Set<String>> cList = readClusterFromOlkResFile(olkResPath1);
		Set<String>[] clusteringX = new Set[cList.size()];
		clusteringX = cList.toArray(clusteringX);

		List<Set<String>> cList2 = readClusterFromOlkResFile(olkResPath2);
		Set<String>[] clusteringY = new Set[cList2.size()];
		clusteringY = cList2.toArray(clusteringY);
		
		Map<String, Set<Integer>> tidToClusters1 = getTidToClusterMap(clusteringX);
		Map<String, Set<Integer>> tidToClusters2 = getTidToClusterMap(clusteringY);
		OverlapMatrix om = new OverlapMatrix(tidToClusters1, tidToClusters2);
		OverlapMatrix omFlipped = om.getFlippedOM();
		double res = 1.0 - 0.5 * (VIoneSide(omFlipped, clusteringX, clusteringY) + VIoneSide(om, clusteringY, clusteringX));
		System.out.println("LFK-NMI between " + olkResPath1 + " and " + olkResPath2 + ": " + res);
		return res;
	}
	
	public double getLfkNmiOlkGroundTruth(String olkResPath, String groundTruthTidPath) throws Exception {
		List<Set<String>> cList = readClusterFromOlkResFile(olkResPath);
		Set<String>[] clusteringX = new Set[cList.size()];
		clusteringX = cList.toArray(clusteringX);
		
		List<Set<String>> cList2 = readClusterFromTestFile(groundTruthTidPath);
		Set<String>[] clusteringY = new Set[cList2.size()];
		clusteringY = cList2.toArray(clusteringY);
		
		Map<String, Set<Integer>> tidToClusters1 = getTidToClusterMap(clusteringX);
		Map<String, Set<Integer>> tidToClusters2 = getTidToClusterMap(clusteringY);
		OverlapMatrix om = new OverlapMatrix(tidToClusters1, tidToClusters2);
		OverlapMatrix omFlipped = om.getFlippedOM();
		double res = 1.0 - 0.5 * (VIoneSide(omFlipped, clusteringX, clusteringY) + VIoneSide(om, clusteringY, clusteringX));
		System.out.println("LFK-NMI between " + olkResPath + " and " + groundTruthTidPath + ": " + res);
		return res;
	}
}
